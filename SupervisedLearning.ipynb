{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning\n",
    "\n",
    "Supervised learning is the branch of Machine Learning (ML) that involves predicting labels, such as 'Survived' or 'Not'. Such models learn from labelled data, which is data that includes whether a passenger survived (called \"model training\"), and then predict on unlabelled data.\n",
    "\n",
    "* You want to build a model that learns patterns in the training set, and\n",
    "* You then use the model to make predictions on the test set.\n",
    "\n",
    "## End-to-End ML Project Steps:\n",
    "1. Undersatnd the problem\n",
    "2. Get the data\n",
    "3. Perform an Exploratory Data Analysis (EDA) on your data set;\n",
    "4. Prepare the data for traning\n",
    "5. Select the proper model and train it\n",
    "6. Iterate 3-5. You will do more EDA and build another model;\n",
    "7. Engineer features: take the features that you already have and combine them or extract more information from them to eventually come to the last point, which is\n",
    "8. Get a model that performs better and present your solution.\n",
    "\n",
    "### The problem\n",
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "***apply the tools of machine learning to predict which passengers survived the tragedy.***\n",
    "\n",
    "### Setup and Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Figures inline and set visualization style\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "\n",
    "# Import data\n",
    "df_train = ____\n",
    "df_test = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# view first lines of training data\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What are all these features? Check out the Kaggle data documentation [here](https://www.kaggle.com/c/titanic/data).\n",
    "\n",
    "### Important note on terminology:\n",
    "\n",
    "* The target variable is the one you are trying to predict (Survival);\n",
    "* Other variables are known as features (or predictor variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# view first lines of test data\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the DataFrame .info() method to check out datatypes, missing values and more (of df_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use the DataFrame .describe() method to check out summary statistics of numeric columns (of df_train)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use seaborn to build a bar plot of Titanic survival (your target variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: In the training set, less people survived than didn't. Let's then build a first model that **predict that nobody survived**.\n",
    "\n",
    "This is a bad model as we know that people survived. But it gives us a baseline: any model that we build later needs to do better than this one.\n",
    "\n",
    "* Create a column 'Survived' for df_test that encodes 'did not survive' for all rows;\n",
    "* Save 'PassengerId' and 'Survived' columns of df_test to a .csv and submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "____ = 0\n",
    "df_test[['PassengerId', 'Survived']].____ #save at './data/predictions/bad_pred.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use seaborn to build a bar plot of the Titanic dataset feature 'Sex' of df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use seaborn to build bar plots of the Titanic dataset feature 'Survived' split (faceted) over the feature 'Sex'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: Women were more likely to survive than men.\n",
    "\n",
    "* Use pandas to figure out how many women and how many men survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use pandas to calculate the survival rate for males and females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_females = ____\n",
    "females_survived = ____\n",
    "female_survival = females_survived / num_females\n",
    "num_males = ____\n",
    "males_survived = ____\n",
    "male_survival = males_survived / num_men\n",
    "print('female survival = ', female_survival)\n",
    "print('male survival = ', male_survival)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now build a second model and predict that all women survived and all men didn't. Once again, this is an unrealistic model, but it will provide a baseline against which to compare future models.\n",
    "\n",
    "* Create a column 'Survived' for df_test that encodes the above prediction.\n",
    "* Save 'PassengerId' and 'Survived' columns of df_test to a .csv and submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test['Survived'] = ____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test[['PassengerId', 'Survived']].to_csv('data/predictions/women_survive.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use ``seaborn`` to build bar plots of the Titanic dataset feature ``'Survived'`` split (faceted) over the feature ``'Pclass'``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x='Survived', col='Pclass', kind='count', data=df_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: Passengers that travelled in first class were more likely to survive. On the other hand, passengers travelling in third class were more unlikely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use `seaborn` to build bar plots of the Titanic dataset feature `'Survived'` split (faceted) over the feature `'Embarked'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.factorplot(x='Survived', col='Embarked', kind='count', data=df_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: Passengers that embarked in Southampton were less likely to survive.\n",
    "\n",
    "## EDA with Numeric features\n",
    "\n",
    "* Use seaborn to plot a histogram of the 'Fare' column of df_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.distplot(df_train.Fare, kde=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: Most passengers paid less than 100 for travelling with the Titanic.\n",
    "\n",
    "* Use a pandas plotting method to plot the column 'Fare' for each value of 'Survived' on the same plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.groupby('Survived').Fare.hist(alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: It looks as though those that paid more had a higher chance of surviving.\n",
    "\n",
    "* Use seaborn to plot a histogram of the 'Age' column of df_train. You'll need to drop null values before doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_drop = df_train.dropna()\n",
    "sns.distplot(df_train_drop.Age, kde=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plot a strip plot & a swarm plot of 'Fare' with 'Survived' on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.stripplot(x='Survived', y='Fare', data=df_train, alpha=0.3, jitter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.swarmplot(x='Survived', y='Fare', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: Fare definitely seems to be correlated with survival aboard the Titanic.\n",
    "\n",
    "* Use the DataFrame method .describe() to check out summary statistics of 'Fare' as a function of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train.groupby('Survived').Fare.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use seaborn to plot a scatter plot of 'Age' against 'Fare', colored by 'Survived'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.lmplot(x='Age', y='Fare', hue='Survived', data=df_train, fit_reg=False, scatter_kws={'alpha':0.5});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Take-away**: It looks like those who survived either paid quite a bit for their ticket or they were young.\n",
    "\n",
    "* Use seaborn to create a pairplot of df_train, colored by 'Survived'. A pairplot is a great way to display most of the information that you have already discovered in a single grid of plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_train_drop, hue='Survived');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your first ML model\n",
    "\n",
    "* Below, you will drop the target 'Survived' from the training dataset and create a new DataFrame data that consists of training and test sets combined;\n",
    "* But first, you'll store the target variable of the training data for safe keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Store target variable of training data in a safe place\n",
    "survived_train = ____\n",
    "\n",
    "data = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check out your new DataFrame data using the info() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Impute missing numerical variables, using the median\n",
    "data['Age'] = ____\n",
    "data['Fare'] = ____\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# change 'male' and 'female' to numbers using pandas function get_dummies\n",
    "data = ____\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select the columns ['Sex_male', 'Fare', 'Age','Pclass', 'SibSp'] from your DataFrame to build your first machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select the columns for ml model\n",
    "data = ____\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Build a decision tree classifier\n",
    "\n",
    "What is a Decision tree classsifier? It is a tree that allows you to classify data points (aka predict target variables) based on feature variables.\n",
    "\n",
    "* You first fit such a model to your training data, which means deciding (based on the training data) which decisions will split at each branching point in the tree: e.g., that the first branch is on 'Male' or not and that 'Male' results in a prediction of 'Dead'.\n",
    "\n",
    "\n",
    "* Before fitting a model to your data, split it back into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = data.iloc[:891]\n",
    "data_test = data.iloc[891:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You'll use scikit-learn, which requires your data as arrays, not DataFrames so transform them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = ____\n",
    "y = ____\n",
    "test = ____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you get to build your decision tree classifier! First create such a model with max_depth=3 and then fit it your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Instantiate model and fit to data\n",
    "clf = ____\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Make predictions on your test set, create a new column 'Survived' and store your predictions in it. Save 'PassengerId' and 'Survived' columns of df_test to a .csv and submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make prediction and store in 'Survived' column of df_test\n",
    "y_pred = ____\n",
    "df_test['Survived'] = y_pred\n",
    "df_test[['PassengerId', 'Survived']].to_csv('data/predictions/1st_dec_tree.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why would you choose max_depth=3 ?\n",
    "\n",
    "The depth of the tree is known as a hyperparameter, which means a parameter we need to decide before we fit the model to the data. If we choose a larger max_depth, we'll get a more complex decision boundary.\n",
    "\n",
    "* If our decision boundary is too complex we can overfit to the data, which means that our model will be describing noise as well as signal.\n",
    "\n",
    "* If our max_depth is too small, we may be underfitting the data, meaning that our model doesn't contain enough of the signal.\n",
    "\n",
    "**How do we tell whether we're overfitting or underfitting?** Note: this is also referred to as the bias-variance trade-off and we won;t go into details on that here.\n",
    "\n",
    "One way is to hold out a test set from our training data. We can then fit the model to our training data, make predictions on our test set and see how well our prediction does on the test set.\n",
    "\n",
    "* You'll now do this: split your original training data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Iterate over values of max_depth ranging from 1 to 9 and plot the accuracy of the models on training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup arrays to store train and test accuracies\n",
    "dep = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(dep))\n",
    "test_accuracy = np.empty(len(dep))\n",
    "\n",
    "# Loop over different values of k\n",
    "for i, k in enumerate(dep):\n",
    "    # Setup a Decision Tree Classifier\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=k)\n",
    "\n",
    "    # Fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the training set\n",
    "    train_accuracy[i] = clf.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[i] = clf.score(X_test, y_test)\n",
    "\n",
    "# Generate plot\n",
    "plt.title('clf: Varying depth of tree')\n",
    "plt.plot(dep, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(dep, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Depth of tree')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
